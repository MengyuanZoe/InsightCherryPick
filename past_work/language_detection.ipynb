{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook utilizes the detect language python api to determine the language of the comment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import detectlanguage\n",
    "import config\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detectlanguage.configuration.api_key = \"your detectlanguage_api_key\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note that this emoji detector also throws out foriegn text\n",
    "## e.g., 'Sab√≠a'\n",
    "def is_emoji(text):\n",
    "    try:\n",
    "        text.encode('ascii')\n",
    "        return False\n",
    "    except UnicodeEncodeError:\n",
    "        return True\n",
    "\n",
    "def is_username(text):\n",
    "    if re.match(\"@[A-Za-z0-9_.]+\",text):\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "def is_hashtag(text):\n",
    "    if re.match(\"#[A-Za-z0-9_.]+\",text):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def cleaned_text_for_langdect(word_list):\n",
    "    return ' '.join([word.lower() for word in word_list \n",
    "                     if not is_emoji(word) \n",
    "                     and not is_username(word) \n",
    "                     and not is_hashtag(word)])\n",
    "\n",
    "def get_language(text):\n",
    "    lang_output = detectlanguage.detect(text)\n",
    "    if lang_output:\n",
    "        lang_dict = dict(lang_output[0])\n",
    "        lang_dict['text'] = text\n",
    "        return lang_dict\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the detect language map\n",
    "with open('detect_language_key.json','r') as input:\n",
    "    language_key = json.load(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Imports and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "post_df = pd.read_csv('loreal_comments.csv').sort_values(by=['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepping comments for language detection\n",
    "comments = list(post_df.text)\n",
    "comments_split = [comment.split() for comment in comments]\n",
    "text_list = [cleaned_text_for_langdect(word_list) for word_list in comments_split]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting language in comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Analyzing each comment and adding to data list.\n",
    "comment_languages_found = []\n",
    "for text in text_list:\n",
    "    lang_dict = get_language(text)\n",
    "    if lang_dict:\n",
    "        comment_languages_found.append(lang_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Screening for only languages with high confidence scores from algorithm.\n",
    "reliable_langs_found = [lang_dict for lang_dict in comment_languages_found if lang_dict['isReliable'] == True]\n",
    "languages_found = [lang_dict['language'] for lang_dict in reliable_langs_found]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs_series = pd.Series([language_key[lang_initials] for lang_initials in languages_found]).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs_df = pd.DataFrame(langs_series)\n",
    "langs_df.reset_index(level=0, inplace=True)\n",
    "langs_df.columns = ['language','comment_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top4_df = langs_df.sort_values(by=['comment_count'],ascending=False).iloc[:4]\n",
    "other_count = langs_df.iloc[4:]['comment_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5_df = top4_df.append({'language':'Other','comment_count':other_count},ignore_index=True)\n",
    "total = top5_df['comment_count'].sum()\n",
    "top5_df['normalized'] = top5_df['comment_count']/float(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([54,3,2,2,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x/x.sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
