{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from string import punctuation, digits, ascii_lowercase\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bios_df = pd.read_csv('bio.csv')\n",
    "caps_df = pd.read_csv('caption.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bios = bios_df.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caps = caps_df.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "escapes = ''.join([chr(char) for char in range(1, 32)])\n",
    "removeables = escapes + digits \n",
    "ig_adds = ['@','#']\n",
    "ig_stops = ['com']\n",
    "stops = [str(word) for word in stopwords.words('english')] + list(ascii_lowercase) + ig_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_text(text):\n",
    "    ''' This function takes a review string and removes all escape sequences,\n",
    "        digits, punctuation, http links, and stop words. Furthermore, every\n",
    "        word in the string will be stemmed using nltk's snowball stemmer.\n",
    "        Every word is also transformed to be lowercase.'''\n",
    "    \n",
    "    text = re.sub(r\"http\\S+\", \" \", text)\n",
    "    regex = re.compile('[%s]' % re.escape(punctuation+escapes))\n",
    "    text = regex.sub(' ', text)\n",
    "    text = text.translate(str.maketrans('','',removeables))\n",
    "    text = ' '.join([word.lower() for word in text.split() if word.lower() not in set(stops)])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# bios_split = [parse_text(bio[0]).split(' ') for bio in bios]\n",
    "# caps_split = [parse_text(cap[0]).split(' ') for cap in caps]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = bios_split+caps_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(iter=5,workers=4,size=100,min_count=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-05 16:27:06,044 : INFO : collecting all words and their counts\n",
      "2017-03-05 16:27:06,046 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-03-05 16:27:06,094 : INFO : PROGRESS: at sentence #10000, processed 82692 words, keeping 29053 word types\n",
      "2017-03-05 16:27:06,147 : INFO : PROGRESS: at sentence #20000, processed 164583 words, keeping 48363 word types\n",
      "2017-03-05 16:27:06,195 : INFO : PROGRESS: at sentence #30000, processed 245994 words, keeping 64154 word types\n",
      "2017-03-05 16:27:06,243 : INFO : PROGRESS: at sentence #40000, processed 328138 words, keeping 81052 word types\n",
      "2017-03-05 16:27:06,312 : INFO : PROGRESS: at sentence #50000, processed 419591 words, keeping 97537 word types\n",
      "2017-03-05 16:27:06,357 : INFO : PROGRESS: at sentence #60000, processed 518413 words, keeping 112024 word types\n",
      "2017-03-05 16:27:06,399 : INFO : PROGRESS: at sentence #70000, processed 610840 words, keeping 124793 word types\n",
      "2017-03-05 16:27:06,462 : INFO : PROGRESS: at sentence #80000, processed 753318 words, keeping 147187 word types\n",
      "2017-03-05 16:27:06,516 : INFO : PROGRESS: at sentence #90000, processed 864629 words, keeping 161138 word types\n",
      "2017-03-05 16:27:06,587 : INFO : PROGRESS: at sentence #100000, processed 985297 words, keeping 175756 word types\n",
      "2017-03-05 16:27:06,627 : INFO : PROGRESS: at sentence #110000, processed 1093957 words, keeping 189378 word types\n",
      "2017-03-05 16:27:06,678 : INFO : PROGRESS: at sentence #120000, processed 1205609 words, keeping 201796 word types\n",
      "2017-03-05 16:27:06,741 : INFO : PROGRESS: at sentence #130000, processed 1342663 words, keeping 217159 word types\n",
      "2017-03-05 16:27:06,791 : INFO : PROGRESS: at sentence #140000, processed 1456952 words, keeping 230057 word types\n",
      "2017-03-05 16:27:06,841 : INFO : PROGRESS: at sentence #150000, processed 1558822 words, keeping 242046 word types\n",
      "2017-03-05 16:27:06,890 : INFO : PROGRESS: at sentence #160000, processed 1654944 words, keeping 251662 word types\n",
      "2017-03-05 16:27:06,947 : INFO : PROGRESS: at sentence #170000, processed 1758399 words, keeping 265077 word types\n",
      "2017-03-05 16:27:07,013 : INFO : PROGRESS: at sentence #180000, processed 1880889 words, keeping 281881 word types\n",
      "2017-03-05 16:27:07,083 : INFO : PROGRESS: at sentence #190000, processed 2002712 words, keeping 299440 word types\n",
      "2017-03-05 16:27:07,160 : INFO : PROGRESS: at sentence #200000, processed 2160960 words, keeping 315539 word types\n",
      "2017-03-05 16:27:07,238 : INFO : PROGRESS: at sentence #210000, processed 2301910 words, keeping 328787 word types\n",
      "2017-03-05 16:27:07,292 : INFO : PROGRESS: at sentence #220000, processed 2413285 words, keeping 341278 word types\n",
      "2017-03-05 16:27:07,369 : INFO : PROGRESS: at sentence #230000, processed 2517017 words, keeping 352675 word types\n",
      "2017-03-05 16:27:07,424 : INFO : PROGRESS: at sentence #240000, processed 2615666 words, keeping 364037 word types\n",
      "2017-03-05 16:27:07,499 : INFO : PROGRESS: at sentence #250000, processed 2768628 words, keeping 379612 word types\n",
      "2017-03-05 16:27:07,571 : INFO : PROGRESS: at sentence #260000, processed 2941156 words, keeping 395713 word types\n",
      "2017-03-05 16:27:07,644 : INFO : PROGRESS: at sentence #270000, processed 3103027 words, keeping 411348 word types\n",
      "2017-03-05 16:27:07,708 : INFO : PROGRESS: at sentence #280000, processed 3234148 words, keeping 424404 word types\n",
      "2017-03-05 16:27:07,765 : INFO : PROGRESS: at sentence #290000, processed 3337067 words, keeping 437805 word types\n",
      "2017-03-05 16:27:07,817 : INFO : PROGRESS: at sentence #300000, processed 3439380 words, keeping 451029 word types\n",
      "2017-03-05 16:27:07,879 : INFO : PROGRESS: at sentence #310000, processed 3531642 words, keeping 463262 word types\n",
      "2017-03-05 16:27:07,940 : INFO : PROGRESS: at sentence #320000, processed 3657161 words, keeping 475289 word types\n",
      "2017-03-05 16:27:07,997 : INFO : PROGRESS: at sentence #330000, processed 3762465 words, keeping 485952 word types\n",
      "2017-03-05 16:27:08,056 : INFO : PROGRESS: at sentence #340000, processed 3869735 words, keeping 497880 word types\n",
      "2017-03-05 16:27:08,117 : INFO : PROGRESS: at sentence #350000, processed 3976154 words, keeping 510106 word types\n",
      "2017-03-05 16:27:08,181 : INFO : PROGRESS: at sentence #360000, processed 4097115 words, keeping 523580 word types\n",
      "2017-03-05 16:27:08,250 : INFO : PROGRESS: at sentence #370000, processed 4212370 words, keeping 534845 word types\n",
      "2017-03-05 16:27:08,302 : INFO : PROGRESS: at sentence #380000, processed 4314371 words, keeping 547042 word types\n",
      "2017-03-05 16:27:08,369 : INFO : PROGRESS: at sentence #390000, processed 4437994 words, keeping 560199 word types\n",
      "2017-03-05 16:27:08,435 : INFO : PROGRESS: at sentence #400000, processed 4540656 words, keeping 570469 word types\n",
      "2017-03-05 16:27:08,486 : INFO : PROGRESS: at sentence #410000, processed 4638708 words, keeping 581074 word types\n",
      "2017-03-05 16:27:08,550 : INFO : PROGRESS: at sentence #420000, processed 4745550 words, keeping 591788 word types\n",
      "2017-03-05 16:27:08,617 : INFO : PROGRESS: at sentence #430000, processed 4846303 words, keeping 602269 word types\n",
      "2017-03-05 16:27:08,671 : INFO : PROGRESS: at sentence #440000, processed 4949488 words, keeping 612502 word types\n",
      "2017-03-05 16:27:08,728 : INFO : PROGRESS: at sentence #450000, processed 5055566 words, keeping 622846 word types\n",
      "2017-03-05 16:27:08,787 : INFO : PROGRESS: at sentence #460000, processed 5155535 words, keeping 632539 word types\n",
      "2017-03-05 16:27:08,847 : INFO : PROGRESS: at sentence #470000, processed 5257754 words, keeping 642784 word types\n",
      "2017-03-05 16:27:08,924 : INFO : PROGRESS: at sentence #480000, processed 5422993 words, keeping 654648 word types\n",
      "2017-03-05 16:27:09,003 : INFO : PROGRESS: at sentence #490000, processed 5625844 words, keeping 667213 word types\n",
      "2017-03-05 16:27:09,065 : INFO : PROGRESS: at sentence #500000, processed 5748825 words, keeping 677153 word types\n",
      "2017-03-05 16:27:09,129 : INFO : PROGRESS: at sentence #510000, processed 5865766 words, keeping 687802 word types\n",
      "2017-03-05 16:27:09,184 : INFO : PROGRESS: at sentence #520000, processed 5979851 words, keeping 697566 word types\n",
      "2017-03-05 16:27:09,334 : INFO : PROGRESS: at sentence #530000, processed 6097842 words, keeping 707672 word types\n",
      "2017-03-05 16:27:09,392 : INFO : PROGRESS: at sentence #540000, processed 6198861 words, keeping 716604 word types\n",
      "2017-03-05 16:27:09,457 : INFO : PROGRESS: at sentence #550000, processed 6295853 words, keeping 726337 word types\n",
      "2017-03-05 16:27:09,535 : INFO : PROGRESS: at sentence #560000, processed 6430586 words, keeping 735454 word types\n",
      "2017-03-05 16:27:09,614 : INFO : PROGRESS: at sentence #570000, processed 6578155 words, keeping 745888 word types\n",
      "2017-03-05 16:27:09,679 : INFO : PROGRESS: at sentence #580000, processed 6708186 words, keeping 755636 word types\n",
      "2017-03-05 16:27:09,753 : INFO : PROGRESS: at sentence #590000, processed 6810718 words, keeping 763797 word types\n",
      "2017-03-05 16:27:09,810 : INFO : PROGRESS: at sentence #600000, processed 6924074 words, keeping 772495 word types\n",
      "2017-03-05 16:27:09,880 : INFO : PROGRESS: at sentence #610000, processed 7036023 words, keeping 780676 word types\n",
      "2017-03-05 16:27:09,957 : INFO : PROGRESS: at sentence #620000, processed 7147942 words, keeping 790087 word types\n",
      "2017-03-05 16:27:10,019 : INFO : PROGRESS: at sentence #630000, processed 7250912 words, keeping 798625 word types\n",
      "2017-03-05 16:27:10,087 : INFO : PROGRESS: at sentence #640000, processed 7347718 words, keeping 807665 word types\n",
      "2017-03-05 16:27:10,155 : INFO : PROGRESS: at sentence #650000, processed 7458250 words, keeping 818831 word types\n",
      "2017-03-05 16:27:10,220 : INFO : PROGRESS: at sentence #660000, processed 7552535 words, keeping 827671 word types\n",
      "2017-03-05 16:27:10,277 : INFO : PROGRESS: at sentence #670000, processed 7641727 words, keeping 836174 word types\n",
      "2017-03-05 16:27:10,341 : INFO : PROGRESS: at sentence #680000, processed 7736020 words, keeping 845060 word types\n",
      "2017-03-05 16:27:10,400 : INFO : PROGRESS: at sentence #690000, processed 7831142 words, keeping 852692 word types\n",
      "2017-03-05 16:27:10,461 : INFO : PROGRESS: at sentence #700000, processed 7927244 words, keeping 860392 word types\n",
      "2017-03-05 16:27:10,540 : INFO : PROGRESS: at sentence #710000, processed 8061745 words, keeping 871843 word types\n",
      "2017-03-05 16:27:10,607 : INFO : PROGRESS: at sentence #720000, processed 8169265 words, keeping 880591 word types\n",
      "2017-03-05 16:27:10,685 : INFO : PROGRESS: at sentence #730000, processed 8337160 words, keeping 891276 word types\n",
      "2017-03-05 16:27:10,776 : INFO : PROGRESS: at sentence #740000, processed 8511656 words, keeping 902242 word types\n",
      "2017-03-05 16:27:10,841 : INFO : PROGRESS: at sentence #750000, processed 8647719 words, keeping 912780 word types\n",
      "2017-03-05 16:27:10,915 : INFO : PROGRESS: at sentence #760000, processed 8755690 words, keeping 923540 word types\n",
      "2017-03-05 16:27:10,990 : INFO : PROGRESS: at sentence #770000, processed 8868428 words, keeping 933559 word types\n",
      "2017-03-05 16:27:11,060 : INFO : PROGRESS: at sentence #780000, processed 8975760 words, keeping 942584 word types\n",
      "2017-03-05 16:27:11,127 : INFO : PROGRESS: at sentence #790000, processed 9076256 words, keeping 954270 word types\n",
      "2017-03-05 16:27:11,197 : INFO : PROGRESS: at sentence #800000, processed 9168713 words, keeping 965224 word types\n",
      "2017-03-05 16:27:11,257 : INFO : PROGRESS: at sentence #810000, processed 9280904 words, keeping 974875 word types\n",
      "2017-03-05 16:27:11,338 : INFO : PROGRESS: at sentence #820000, processed 9406704 words, keeping 984578 word types\n",
      "2017-03-05 16:27:11,412 : INFO : PROGRESS: at sentence #830000, processed 9536033 words, keeping 992808 word types\n",
      "2017-03-05 16:27:11,485 : INFO : PROGRESS: at sentence #840000, processed 9644631 words, keeping 1000911 word types\n",
      "2017-03-05 16:27:11,548 : INFO : PROGRESS: at sentence #850000, processed 9742726 words, keeping 1010993 word types\n",
      "2017-03-05 16:27:11,616 : INFO : PROGRESS: at sentence #860000, processed 9843421 words, keeping 1020628 word types\n",
      "2017-03-05 16:27:11,694 : INFO : PROGRESS: at sentence #870000, processed 9964469 words, keeping 1031588 word types\n",
      "2017-03-05 16:27:11,770 : INFO : PROGRESS: at sentence #880000, processed 10082938 words, keeping 1041709 word types\n",
      "2017-03-05 16:27:11,827 : INFO : PROGRESS: at sentence #890000, processed 10152945 words, keeping 1047840 word types\n",
      "2017-03-05 16:27:11,888 : INFO : PROGRESS: at sentence #900000, processed 10242972 words, keeping 1055339 word types\n",
      "2017-03-05 16:27:11,964 : INFO : PROGRESS: at sentence #910000, processed 10356113 words, keeping 1066044 word types\n",
      "2017-03-05 16:27:12,028 : INFO : PROGRESS: at sentence #920000, processed 10454846 words, keeping 1077343 word types\n",
      "2017-03-05 16:27:12,100 : INFO : PROGRESS: at sentence #930000, processed 10551978 words, keeping 1087932 word types\n",
      "2017-03-05 16:27:12,163 : INFO : PROGRESS: at sentence #940000, processed 10639280 words, keeping 1101703 word types\n",
      "2017-03-05 16:27:12,233 : INFO : PROGRESS: at sentence #950000, processed 10727904 words, keeping 1114188 word types\n",
      "2017-03-05 16:27:12,317 : INFO : PROGRESS: at sentence #960000, processed 10871876 words, keeping 1123424 word types\n",
      "2017-03-05 16:27:12,395 : INFO : PROGRESS: at sentence #970000, processed 11009208 words, keeping 1133115 word types\n",
      "2017-03-05 16:27:12,468 : INFO : PROGRESS: at sentence #980000, processed 11148843 words, keeping 1144050 word types\n",
      "2017-03-05 16:27:12,539 : INFO : PROGRESS: at sentence #990000, processed 11257740 words, keeping 1151337 word types\n",
      "2017-03-05 16:27:12,607 : INFO : PROGRESS: at sentence #1000000, processed 11344981 words, keeping 1161817 word types\n",
      "2017-03-05 16:27:12,678 : INFO : PROGRESS: at sentence #1010000, processed 11473349 words, keeping 1171049 word types\n",
      "2017-03-05 16:27:12,768 : INFO : PROGRESS: at sentence #1020000, processed 11628886 words, keeping 1180926 word types\n",
      "2017-03-05 16:27:12,840 : INFO : PROGRESS: at sentence #1030000, processed 11760818 words, keeping 1191212 word types\n",
      "2017-03-05 16:27:12,919 : INFO : PROGRESS: at sentence #1040000, processed 11890423 words, keeping 1200541 word types\n",
      "2017-03-05 16:27:12,994 : INFO : PROGRESS: at sentence #1050000, processed 12007328 words, keeping 1208578 word types\n",
      "2017-03-05 16:27:13,081 : INFO : PROGRESS: at sentence #1060000, processed 12146782 words, keeping 1217416 word types\n",
      "2017-03-05 16:27:13,162 : INFO : PROGRESS: at sentence #1070000, processed 12287990 words, keeping 1225510 word types\n",
      "2017-03-05 16:27:13,248 : INFO : PROGRESS: at sentence #1080000, processed 12464566 words, keeping 1233368 word types\n",
      "2017-03-05 16:27:13,305 : INFO : collected 1238290 word types from a corpus of 12558681 raw words and 1086736 sentences\n",
      "2017-03-05 16:27:13,307 : INFO : Loading a fresh vocabulary\n",
      "2017-03-05 16:27:14,234 : INFO : min_count=20 retains 51279 unique words (4% of original 1238290, drops 1187011)\n",
      "2017-03-05 16:27:14,235 : INFO : min_count=20 leaves 10007878 word corpus (79% of original 12558681, drops 2550803)\n",
      "2017-03-05 16:27:14,493 : INFO : deleting the raw counts dictionary of 1238290 items\n",
      "2017-03-05 16:27:14,542 : INFO : sample=0.001 downsamples 12 most-common words\n",
      "2017-03-05 16:27:14,543 : INFO : downsampling leaves estimated 9922428 word corpus (99.1% of prior 10007878)\n",
      "2017-03-05 16:27:14,545 : INFO : estimated required memory for 51279 words and 100 dimensions: 66662700 bytes\n",
      "2017-03-05 16:27:14,794 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "model.build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-05 16:27:21,487 : INFO : training model with 4 workers on 51279 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2017-03-05 16:27:21,488 : INFO : expecting 1086736 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-03-05 16:27:22,511 : INFO : PROGRESS: at 2.39% examples, 1055982 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-05 16:27:23,518 : INFO : PROGRESS: at 4.38% examples, 1023008 words/s, in_qsize 6, out_qsize 1\n",
      "2017-03-05 16:27:24,532 : INFO : PROGRESS: at 6.49% examples, 1041377 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-05 16:27:25,534 : INFO : PROGRESS: at 8.86% examples, 1064728 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-05 16:27:26,538 : INFO : PROGRESS: at 11.05% examples, 1089224 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-05 16:27:27,540 : INFO : PROGRESS: at 13.44% examples, 1094842 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-05 16:27:28,546 : INFO : PROGRESS: at 15.78% examples, 1101409 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-05 16:27:29,550 : INFO : PROGRESS: at 18.27% examples, 1104829 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-05 16:27:30,554 : INFO : PROGRESS: at 20.38% examples, 1111636 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-05 16:27:31,560 : INFO : PROGRESS: at 22.83% examples, 1113506 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-05 16:27:32,564 : INFO : PROGRESS: at 24.97% examples, 1120167 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-05 16:27:33,566 : INFO : PROGRESS: at 27.36% examples, 1118226 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-05 16:27:34,578 : INFO : PROGRESS: at 29.61% examples, 1121413 words/s, in_qsize 7, out_qsize 3\n",
      "2017-03-05 16:27:35,589 : INFO : PROGRESS: at 32.00% examples, 1124989 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-05 16:27:36,589 : INFO : PROGRESS: at 34.22% examples, 1124727 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-05 16:27:37,589 : INFO : PROGRESS: at 36.72% examples, 1124309 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-05 16:27:38,596 : INFO : PROGRESS: at 39.06% examples, 1125999 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-05 16:27:39,600 : INFO : PROGRESS: at 41.38% examples, 1126735 words/s, in_qsize 8, out_qsize 0\n",
      "2017-03-05 16:27:40,604 : INFO : PROGRESS: at 43.70% examples, 1129389 words/s, in_qsize 8, out_qsize 0\n",
      "2017-03-05 16:27:41,604 : INFO : PROGRESS: at 45.77% examples, 1127438 words/s, in_qsize 6, out_qsize 1\n",
      "2017-03-05 16:27:42,605 : INFO : PROGRESS: at 48.13% examples, 1125686 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-05 16:27:43,608 : INFO : PROGRESS: at 50.35% examples, 1129033 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-05 16:27:44,614 : INFO : PROGRESS: at 52.77% examples, 1128009 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-05 16:27:45,614 : INFO : PROGRESS: at 55.01% examples, 1129719 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-05 16:27:46,620 : INFO : PROGRESS: at 57.55% examples, 1128071 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-05 16:27:47,624 : INFO : PROGRESS: at 59.63% examples, 1129323 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-05 16:27:48,629 : INFO : PROGRESS: at 61.95% examples, 1128071 words/s, in_qsize 8, out_qsize 0\n",
      "2017-03-05 16:27:49,629 : INFO : PROGRESS: at 64.18% examples, 1128550 words/s, in_qsize 6, out_qsize 1\n",
      "2017-03-05 16:27:50,632 : INFO : PROGRESS: at 66.42% examples, 1129128 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-05 16:27:51,637 : INFO : PROGRESS: at 68.82% examples, 1129206 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-05 16:27:52,639 : INFO : PROGRESS: at 70.97% examples, 1130883 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-05 16:27:53,640 : INFO : PROGRESS: at 73.41% examples, 1131154 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-05 16:27:54,647 : INFO : PROGRESS: at 75.69% examples, 1131019 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-05 16:27:55,659 : INFO : PROGRESS: at 78.15% examples, 1130162 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-05 16:27:56,660 : INFO : PROGRESS: at 80.25% examples, 1131528 words/s, in_qsize 8, out_qsize 0\n",
      "2017-03-05 16:27:57,660 : INFO : PROGRESS: at 82.71% examples, 1131411 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-05 16:27:58,665 : INFO : PROGRESS: at 84.87% examples, 1132495 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-05 16:27:59,680 : INFO : PROGRESS: at 87.23% examples, 1131602 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-05 16:28:00,687 : INFO : PROGRESS: at 89.45% examples, 1131820 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-05 16:28:01,688 : INFO : PROGRESS: at 91.75% examples, 1132237 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-05 16:28:02,695 : INFO : PROGRESS: at 94.04% examples, 1132475 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-05 16:28:03,697 : INFO : PROGRESS: at 96.57% examples, 1132503 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-05 16:28:04,699 : INFO : PROGRESS: at 98.92% examples, 1132881 words/s, in_qsize 7, out_qsize 0\n",
      "2017-03-05 16:28:05,252 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-03-05 16:28:05,255 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-03-05 16:28:05,258 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-03-05 16:28:05,264 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-03-05 16:28:05,265 : INFO : training on 62793405 raw words (49612243 effective words) took 43.8s, 1133758 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49612243"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-05 16:28:30,618 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('curves', 0.6837259531021118),\n",
       " ('diva', 0.674258828163147),\n",
       " ('underwear', 0.6699062585830688),\n",
       " ('hunk', 0.6642636060714722),\n",
       " ('fierce', 0.6609104871749878),\n",
       " ('curvy', 0.650741696357727),\n",
       " ('sassy', 0.6392788290977478),\n",
       " ('girly', 0.6227083802223206),\n",
       " ('brunette', 0.6218582391738892),\n",
       " ('skinny', 0.615222692489624)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['sexy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-03-05 16:29:06,401 : INFO : saving Word2Vec object under instagram_language.model, separately None\n",
      "2017-03-05 16:29:06,403 : INFO : not storing attribute syn0norm\n",
      "2017-03-05 16:29:06,404 : INFO : not storing attribute cum_table\n",
      "2017-03-05 16:29:07,288 : INFO : saved instagram_language.model\n"
     ]
    }
   ],
   "source": [
    "model.save('instagram_language.model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
