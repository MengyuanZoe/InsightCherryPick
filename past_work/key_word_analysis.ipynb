{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides some simple tools to extract the top occuring key words from comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import re\n",
    "import unicodedata as ud\n",
    "import string \n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions and utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_username(text):\n",
    "    if re.match(\"@[A-Za-z0-9_.]+\",text):\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "def is_hashtag(text):\n",
    "    if re.match(\"#[A-Za-z0-9_.]+\",text):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "## regular expression for finding unicode\n",
    "unicode_re = re.compile(u'['\n",
    "    u'\\U0001F300-\\U0001F64F'\n",
    "    u'\\U0001F680-\\U0001F6FF'\n",
    "    u'\\u2600-\\u26FF\\u2700-\\u27BF]+', \n",
    "    re.UNICODE)\n",
    "\n",
    "skintone_re = re.compile(u'[\\U0001f3fb-\\U0001f3ff]+', re.UNICODE)\n",
    "\n",
    "def strip_unicode(text):\n",
    "    return unicode_re.sub('',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the stopword list. Nltk, with multiple langs.\n",
    "# plus additional words unique to this corpus.\n",
    "\n",
    "stops = []\n",
    "languages = ['english','spanish','french']\n",
    "for language in languages:\n",
    "    stops += stopwords.words(language)\n",
    "    \n",
    "stops += list(string.ascii_letters)\n",
    "\n",
    "username = 'lorealmakeup'    \n",
    "additional_stopwords = ['',' ',username]\n",
    "stops += additional_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To remove punction from comments.\n",
    "translator = str.maketrans('', '', string.punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Imports and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_df = pd.read_csv('loreal_comments.csv').sort_values(by=['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning list of comments into the list of all words\n",
    "comments = list(post_df.text)\n",
    "comments_split = [comment.split() for comment in comments]\n",
    "# Flattening list, removing puncs, lowercasing all words, and removing emojis and usernames. \n",
    "words = [strip_unicode(item).lower().translate(translator).strip() for sublist in comments_split for item in sublist if not is_username(item)]\n",
    "# Removing stopwords.\n",
    "clean_words = [word for word in words if word not in stops and len(word)>=2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "love         19\n",
       "shade        13\n",
       "colour       10\n",
       "color        10\n",
       "beautiful    10\n",
       "jadore        5\n",
       "perfect       5\n",
       "need          4\n",
       "lovely        4\n",
       "pretty        4\n",
       "couleur       4\n",
       "nice          4\n",
       "like          4\n",
       "wow           4\n",
       "gadhi         3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(clean_words).value_counts().head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hash tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hash_tags = [item.lower() for sublist in comments_split for item in sublist if is_hashtag(item)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#lovecampaign    1\n",
       "#euquero         1\n",
       "#simplissime     1\n",
       "#want            1\n",
       "#loveit‚ù§Ô∏è        1\n",
       "#efficace        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(hash_tags).value_counts().head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grabbing just the comments\n",
    "comments = post_df.text\n",
    "## Stripping out only the emojis in the string\n",
    "emoji_strings = [''.join(re.findall(unicode_re,comment)) for comment in comments]\n",
    "## Spliting into individual emojis, removing all skin tone emojis\n",
    "emojis = [emoji for emojis in emoji_strings for emoji in emojis if not re.match(skintone_re,emoji)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "üòç    108\n",
       "‚ù§     27\n",
       "üëå     14\n",
       "üíó      9\n",
       "üëç      8\n",
       "üíì      8\n",
       "üò≠      7\n",
       "üëè      6\n",
       "üíÑ      6\n",
       "üå∏      6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(emojis).value_counts().head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
